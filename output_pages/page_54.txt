Section 1.7
The Operating System Manages the Hardware
53
Figure 1.12
Process context
switching.
Process A
read
Process B
User code
Kernel code
Kernel code
User code
User code
Context
switch
Context
switch
Time
Disk interrupt
Return
from read
then passing control to the new process. The new process picks up exactly where
it left off. Figure 1.12 shows the basic idea for our example hello scenario.
There are two concurrent processes in our example scenario: the shell process
and the hello process. Initially, the shell process is running alone, waiting for input
on the command line. When we ask it to run the hello program, the shell carries
out our request by invoking a special function known as a system call that passes
control to the operating system. The operating system saves the shell’s context,
creates a new hello process and its context, and then passes control to the new
hello process. After hello terminates, the operating system restores the context
of the shell process and passes control back to it, where it waits for the next
command-line input.
As Figure 1.12 indicates, the transition from one process to another is man-
aged by the operating system kernel. The kernel is the portion of the operating
system code that is always resident in memory. When an application program
requires some action by the operating system, such as to read or write a ﬁle, it
executes a special system call instruction, transferring control to the kernel. The
kernel then performs the requested operation and returns back to the application
program. Note that the kernel is not a separate process. Instead, it is a collection
of code and data structures that the system uses to manage all the processes.
Implementing the process abstraction requires close cooperation between
both the low-level hardware and the operating system software. We will explore
how this works, and how applications can create and control their own processes,
in Chapter 8.
1.7.2
Threads
Although we normally think of a process as having a single control ﬂow, in modern
systems a process can actually consist of multiple execution units, called threads,
each running in the context of the process and sharing the same code and global
data. Threads are an increasingly important programming model because of the
requirement for concurrency in network servers, because it is easier to share data
between multiple threads than between multiple processes, and because threads
are typically more efﬁcient than processes. Multi-threading is also one way to make
programs run faster when multiple processors are available, as we will discuss in
