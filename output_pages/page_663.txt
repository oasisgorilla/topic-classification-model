662
Chapter 6
The Memory Hierarchy
Figure 6.34
Line matching and
word selection in a set
associative cache.
0
1
m–1
0
2
3
4
5
6
7
1
1
1001
0110
t bits
Tag
Set index Block offset
s bits
b bits
= ?
w0
w1
w2
w3
0110
i
100
= 1?   (1) The valid bit must be set.
Selected set (i):
(2) The tag bits in one 
of the cache lines 
must match the tag 
bits in the address.
(3) If (1) and (2), then 
cache hit, and
block offset selects 
starting byte.
Figure 6.34 shows the basic idea of line matching in an associative cache. An
important idea here is that any line in the set can contain any of the memory blocks
that map to that set. So the cache must search each line in the set for a valid line
whose tag matches the tag in the address. If the cache ﬁnds such a line, then we
have a hit and the block offset selects a word from the block, as before.
Line Replacement on Misses in Set Associative Caches
If the word requested by the CPU is not stored in any of the lines in the set, then
we have a cache miss, and the cache must fetch the block that contains the word
from memory. However, once the cache has retrieved the block, which line should
it replace? Of course, if there is an empty line, then it would be a good candidate.
But if there are no empty lines in the set, then we must choose one of the nonempty
lines and hope that the CPU does not reference the replaced line anytime soon.
It is very difﬁcult for programmers to exploit knowledge of the cache replace-
ment policy in their codes, so we will not go into much detail about it here. The
simplest replacement policy is to choose the line to replace at random. Other more
sophisticated policies draw on the principle of locality to try to minimize the prob-
ability that the replaced line will be referenced in the near future. For example, a
least frequently used (LFU) policy will replace the line that has been referenced
the fewest times over some past time window. A least recently used (LRU) policy
will replace the line that was last accessed the furthest in the past. All of these
policies require additional time and hardware. But as we move further down the
memory hierarchy, away from the CPU, the cost of a miss becomes more expen-
sive and it becomes more worthwhile to minimize misses with good replacement
policies.
6.4.4
Fully Associative Caches
A fully associative cache consists of a single set (i.e., E = C/B) that contains all of
the cache lines. Figure 6.35 shows the basic organization.
