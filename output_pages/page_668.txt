Section 6.4
Cache Memories
667
ably cache-friendly programs, we suggest adopting a mental model that assumes
write-back, write-allocate caches. There are several reasons for this suggestion: As
a rule, caches at lower levels of the memory hierarchy are more likely to use write-
back instead of write-through because of the larger transfer times. For example,
virtual memory systems (which use main memory as a cache for the blocks stored
on disk) use write-back exclusively. But as logic densities increase, the increased
complexity of write-back is becoming less of an impediment and we are seeing
write-back caches at all levels of modern systems. So this assumption matches cur-
rent trends. Another reason for assuming a write-back, write-allocate approach is
that it is symmetric to the way reads are handled, in that write-back write-allocate
tries to exploit locality. Thus, we can develop our programs at a high level to exhibit
good spatial and temporal locality rather than trying to optimize for a particular
memory system.
6.4.6
Anatomy of a Real Cache Hierarchy
So far, we have assumed that caches hold only program data. But, in fact, caches
can hold instructions as well as data. A cache that holds instructions only is called
an i-cache. A cache that holds program data only is called a d-cache. A cache that
holds both instructions and data is known as a uniﬁed cache. Modern processors
include separate i-caches and d-caches. There are a number of reasons for this.
With two separate caches, the processor can read an instruction word and a data
word at the same time. I-caches are typically read-only, and thus simpler. The
two caches are often optimized to different access patterns and can have different
block sizes, associativities, and capacities. Also, having separate caches ensures
that data accesses do not create conﬂict misses with instruction accesses, and vice
versa, at the cost of a potential increase in capacity misses.
Figure 6.38 shows the cache hierarchy for the Intel Core i7 processor. Each
CPU chip has four cores. Each core has its own private L1 i-cache, L1 d-cache, and
L2 uniﬁed cache. All of the cores share an on-chip L3 uniﬁed cache. An interesting
feature of this hierarchy is that all of the SRAM cache memories are contained in
the CPU chip.
Figure 6.39 summarizes the basic characteristics of the Core i7 caches.
6.4.7
Performance Impact of Cache Parameters
Cache performance is evaluated with a number of metrics:
Miss rate. The fraction of memory references during the execution of a pro-
gram, or a part of a program, that miss. It is computed as # misses/
# references.
Hit rate. The fraction of memory references that hit. It is computed as
1 −miss rate.
Hit time. The time to deliver a word in the cache to the CPU, including the time
for set selection, line identiﬁcation, and word selection. Hit time is on the
order of several clock cycles for L1 caches.
